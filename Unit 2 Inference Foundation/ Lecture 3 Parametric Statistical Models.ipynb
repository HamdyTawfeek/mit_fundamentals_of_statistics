{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Three <b>Fundamental</b> aspects of <mark><b>statistical inference</b></mark> (Trinity of Statistical Inference): \n",
    "<ul>\n",
    "    <li> <span style=\"color:green\">Estimation</span> : produces a single number, say 69%. That's what machine learning focuses on.</li>\n",
    "    <li><span style=\"color:green\">Confidence Intervals</span>: produce error bars around the estimate.</li>\n",
    "    <li> <span style=\"color:green\">Hypothesis Testing</span>: the basis of data-driven scientific inquiry. We find statistical evidence that something is happening (YES/NO answer to a question)</li>\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  <span style=\"color:blue\">Statistical Modeling </span> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:#6600CC\">The rationale behind statistical modeling</span></h3> \n",
    "<ul> \n",
    "\n",
    "<li>  Let $X_1, ..., X_n$ be $n$ iid copies of $X$. The goal of statistics is to learn the distribution of $X$</li>\n",
    "    \n",
    "    \n",
    "<li> For example: Here is a dataset with number of car accidents: 2, 3, 2, 4, 1,\n",
    "3, 1, 1, 1, 1, 1, 2, 2, 3, 2, 2, 2, 3, 2, 1, 3, 1, 2, 3, . . .\n",
    "    \n",
    "<li>We could make no assumption and try to learn the pmf, That’s 7 parameters to learn.</li>\n",
    "<img src=\"../images/03.pmf.png\"> </img> </li>\n",
    "\n",
    "\n",
    "<li> It's a discrete random variable. To answer any question about this random variable I wnat to understand the distribution of this random variable.</li>\n",
    "<li> To understand the distribution of the random variable, we can estimate every parameter of the PMF but we will need a lot of data to do that. OR,  we what we could do is to try to reduce that. And one thing we can do is to try to say well, there's one distribution that depends only on one parameter,\n",
    "or maybe two parameters, that governs this entire PMF.</li>\n",
    "<li> In this case a candidate distribution that can model integer numbers between zero and inifinity is Poisson. Actually insurance companies use poisson all the time to model the number of car accidents you're going to have during the year.</li>\n",
    "\n",
    "<li>  Assume $X \\sim Poisson(\\lambda)$, where $P(X = x) = \\frac{\\lambda^x}{x!}e^{-\\lambda}$</li>\n",
    "\n",
    "<li> The more parameters you have to learn, the more observations you need. The rule of thumb is if you need to learn two parameters, you need twice as much observations.</li>\n",
    "<li> A good question to ask: Is my underlying distribution a Poisson or not? And that's something we're going to be able to test.</li>\n",
    "<li> It is good to keep the following principle in mind: some models may perform better than others, but there is no such thing as THE correct model. The task of a statistician is to use reasonable assumptions to find a tractable model that gives useful approximations to a given data set.</li>\n",
    "<li> In general it is best to choose the statistical model that incorporates all known information about the sample. Usually this reduces the amount of unknowns in the model or the size of the parameter space.</li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:#6600CC\">Statistical Model</span></h3> \n",
    "\n",
    "> A <mark>model</mark> just means something which is like slightly simpler than what reality actually is, but hopefully captures most of it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Formal Definition</span>\n",
    "\n",
    "Let the observed outcome of a <mark>statistical experiment</mark> be a sample $X_1, ..., X_n$ of n iid random variables in some measurable space $E$ (usually $E \\subseteq R$) and denote by $P$ their common distribution. A statistical model associated to that statistical experiment is a pair:\n",
    "\n",
    "$$(E, \\,\\, (P_\\theta)_{\\theta \\in \\Theta} \\,) \\,,$$\n",
    "\n",
    "\n",
    "__where__\n",
    "\n",
    "- $E$ is called <b>sample space</b>\n",
    "- $(P_\\theta)_{\\theta \\in \\Theta}$ is a <b>family of probability distributions</b> on $E$\n",
    "- $\\Theta$ is any set, called <b>parameter space</b>\n",
    "\n",
    "\n",
    "__Examples of parametric models:__\n",
    "- $\\left(\\{0, 1\\}, (Ber(p))_{p \\in (0, 1)}\\right)$\n",
    "- $\\left(\\mathbb{N}, (Pois(\\lambda))_{\\lambda > 0}\\right)$\n",
    "- $\\left(\\mathbb{R}, (\\mathcal{N}(\\mu, \\sigma^2))_{(\\mu, \\sigma^2) \\in \\mathbb{R} x (0, \\infty)}\\right)$\n",
    "- $\\left(\\mathbb{R^d}, (\\mathcal{N}(\\mu_d, I_d))_{(\\mu,I_d) \\in \\mathbb{R^d}} \\right)$\n",
    "- $\\left(\\mathbb {R}_{+},\\left(\\mathcal U([0,a])\\right)_{a > 0}\\right)$\n",
    "\n",
    "__Examples of nonparametric models:__\n",
    "- If $X_1, ..., X_n \\in \\mathbb {R}$ are i.i.d with unknown unimodal pdf $f$\n",
    "- If $X_1, ..., X_n \\in \\mathbb [0,1]$ are i.i.d with unknown invertiable cdf $F$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__\n",
    "* Sample space can't depend on a parameter. The sample space can, however, be less precise than is desirable. $\\mathbb{R}$ for Poisson is true, but overkill for a parameter that must be an integer greater than 0.\n",
    "\n",
    "* The sample space is the collection of all possible outcomes, which we can package into events to which probabilities cab be assigned. In statistics, data is the main object of study, data are modeled as random variables, and random variables take numerical value. Therefore \"outcomes\" are simply different values that data can take.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"><b>Types of Statistical Models</b> </span>\n",
    "\n",
    "*  The model is <b>parametric</b> if all parameters  $\\Theta \\subseteq \\mathbb{R}^d$ for some $d \\geq 1$ can be specified by a finite number of unknowns. Equivalently, this means that  $\\Theta$   is a subset of  $\\mathbb{R}^m$ . In particular, if $\\Theta \\subset \\mathbb {R}^ m$ , then  $P_\\theta$  is uniquely specified by the  m  entries of the vector  θ. Meaning, the family of distributions can be described with a finite number of parameters. The normal family is parameterized by $\\theta = (\\mu, \\sigma^2)$. \n",
    "* The model is <b>nonparametric</b> if $\\Theta$ is infinite-dimensional. The distribution cannot be specified by a finite amount of information\n",
    "* The model is <b>semiparametric</b> if $\\Theta = \\Theta_1$ x $\\Theta_2$, where $\\Theta_1$ is finite-dimensional and $\\Theta_2$ is infinite-dimensional. $\\Theta$ has two components, for example $(p, f)$ where p is a number between 0 and 1 and $f$ is a function. A function typically lives in an infinite dimensional space.\n",
    "A number between zero and one is a parametric set. we only care to estimate the finite dimensional parameter and\n",
    "the infinite dimensional one is called nuisance parameter.\n",
    "\n",
    "\n",
    "__Note:__\n",
    "* we will assume that the statistical model is well specified. It can reach the actual distribution, i.e, defined such that: $\\exists \\theta  \\, ;\\mathbb{P}_\\theta = \\mathbb{P}$.\n",
    "\n",
    "<img src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='50 50 450 400' width='400' height='400'%3E%3Crect x='80' y='60' width='500' height='500' style='fill:black; stroke:black; fill-opacity:0.7' /%3E%3Ccircle cx='350' cy='200' r='70' stroke='white' stroke-width='3' fill='green' /%3E%3Ccircle cx='390' cy='200' r='2' stroke='red' stroke-width='3' fill='red' /%3E%3Ctext x='397' y='205' fill='blue' font-size='1.7em'%3EP%3C/text%3E%3Ctext x='220' y='127' fill='white' font-size='1.4em'%3E Model parameter space%3C/text%3E%3Ctext x='83' y='410' fill='black' font-size='1.7em'%3EAll probability distributions on E%3C/text%3E%3C/svg%3E\"></img>\n",
    "\n",
    "\n",
    "* This particular $\\theta$ is called the <mark>true parameter</mark> and is always unknown. And the goal of statistical inference will be to estimate it, maybe form some error bars around it or to test it's properties when they have a special meaning $\\theta > 2?\\,\\, \\theta \\neq1/2?$\n",
    "* $\\mathbb{R}^d$ means d-length vector of real numbers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:#6600CC\">Further Examples</span></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"><b>Linear Regression Model</b> </span>\n",
    "\n",
    "\n",
    "If $(X_1, Y_1), ..., (X_n, Y_n) \\in \\mathbb{R}^d \\times \\mathbb{R}$ are iid from the linear regression model \n",
    "\n",
    "$$Y_i = \\beta^T X_i + \\epsilon_i$$\n",
    "\n",
    "__where__\n",
    "\n",
    "- $\\epsilon_i \\overset{iid}{\\sim}\\mathcal{N}(0,1)$ Gaussian noise\n",
    "- unknown $\\beta \\in \\mathbb{R}^d$\n",
    "- $X_i \\sim \\mathcal{N}_d(0, I_d)$ independent of $\\epsilon_i$\n",
    "- $E = \\mathbb{R}^d \\times \\mathbb{R}$\n",
    "- $\\Theta = \\mathbb{R}^d$\n",
    "- $P_\\theta$ is the joint distribution of $(X, Y)$ which can be written as $P_\\theta = \\left(\\mathcal{N}(0, I_d), P(Y|X=x)\\right) = \\left(\\mathcal{N}(0, I_d), \\mathcal{N}(\\beta^T x, 1)\\right)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Note__\n",
    "- A huge amount of work in linear regression is to impose extra structural constraints on beta. For example, if you want sparse linear regression you assume that $\\beta$ is sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"><b>Cox Proportional Hazard Model</b> </span>\n",
    "\n",
    "\n",
    "If $(X_1, Y_1), ..., (X_n, Y_n) \\in \\mathbb{R}^d \\times \\mathbb{R}$\n",
    "\n",
    "- Survival function: $P(X > t) = 1 - F(t)$\n",
    "- The conditional distribution of $Y$ given $X = x$ has CDF $F$ of the form $F(t) = 1 - e^{ - \\int_0^t h(u) e^{(\\beta^Tx)}du}$\n",
    "\n",
    "\n",
    "__Where__\n",
    "\n",
    "- h is an unknown non-negative nuisance function.\n",
    "- $\\beta \\in \\mathbb{R}^d$ is the parameter of interest. \n",
    "- The focus is the term  $e^{\\beta^Tx}$ to find out how $x$ affects $y$ through $\\beta$, and probably not pay as much attention to $h(u)$\n",
    "\n",
    "__Note__\n",
    "\n",
    "- This model that arises a lot in survival analysis. we want to model the probability that people live longer and want to understand what risk factors people have. So they observe a bunch of patients that carry a certain disease over many years. And they want to know the probability that a particular person lives longer than some time little t. So that's the probability that some random variable x exceeds little t.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:#6600CC\">Identifiability of Statistical Models</span></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let $\\{ P_\\theta \\} _{\\theta \\in \\Theta }$ denote a family of distributions that depends on an unknown parameter $\\theta \\in \\Theta$ \n",
    " \n",
    "The parameter  θ  is identifiable if the map $\\theta \\mapsto P_\\theta$ is injective. Here, the notation $\\theta \\mapsto P_\\theta$ denotes a function that takes as input $\\theta \\in \\Theta$ and outputs a probability distribution $P_\\theta$  In other words, if $\\theta \\neq \\theta '$ (and both in  $\\Theta$ ), then $P_\\theta \\neq P_{\\theta '}$\n",
    "\n",
    "\n",
    "__Example__\n",
    "- If $X_i = \\mathbb{I}_{Y_i \\geq 0}$ (indicator function), $Y_1, ...,Y_n \\overset{iid}{\\sim}\\mathcal{N}(\\mu,\\sigma^2)$\n",
    "for some unknown $\\mu \\in \\mathbb{R}$ and $\\sigma^2 > 0$, are unobserved: $\\mu$ and $\\sigma^2$ are not   identifiable but $\\theta = \\mu / \\sigma $ is.\n",
    "\n",
    "__Note__\n",
    "* The notation  $f: S \\to T$  denotes that  $f$  is a function, also called a map , defined on all of a set $S$  and whose outputs lie in a set  $T$ . A function  $f:S \\to T$ is injective if for all  $x,y \\in S$,$f(x) = f(y)$ implies that  $x = y$. Alternatively: a function is injective if we can uniquely recover some input  $x$  based on an output $f(x)$\n",
    "\n",
    "* A parameter is identifiable from a statistical model if only one value for that parameter could have produced the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Watch\n",
    "\n",
    "* <a href=\"https://www.taieb.net/auteurs/Arbuthnot/index.html\"> Expectations and variance of a random vector</a>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
